\documentclass[a4paper, 12pt]{article}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{titlesec}
\usepackage{pgfplots}
\usepackage{pgfplotstable}

\pgfplotsset{width=12cm, compat=1.18}
\newgeometry{left=1.5 cm, right=1.5cm, top=1.5cm, bottom=1.5cm}

\begin{document}


% ---------------------------------- Титульник ----------------------------------
\hypersetup{pageanchor=false}
\begin{titlepage}
 \begin{center}
  \vspace*{1cm}

  \Huge
  \textbf{Лабораторная работа №4}

  \vspace{0.5cm}
  \LARGE
  ``Технология OpenMP. Особенности настройки''

  \vspace{1.5cm}
  Выполнил студент группы Б20-505\\
  \textbf{Сорочан Илья}

  \vfill

  \Large
  Московский Инженерно-Физический Интститут\\
  Москва 2023

 \end{center}
\end{titlepage}


% ---------------------------------- Рабочая среда ----------------------------------

\section{Рабочая среда}

Технические характеристики (вывод \textit{inxi}):
\begin{verbatim}
CPU: 6-core AMD Ryzen 5 4500U with Radeon Graphics (-MCP-)
speed/min/max: 1396/1400/2375 MHz Kernel: 5.15.85-1-MANJARO x86_64 Up: 46m
Mem: 2689.5/7303.9 MiB (36.8%) Storage: 238.47 GiB (12.6% used) Procs: 238
Shell: Zsh inxi: 3.3.24
\end{verbatim}

Используемый компилятор:
\begin{verbatim}
gcc (GCC) 12.2.0
\end{verbatim}

Версия MPI:
\begin{verbatim}
Open MPI 4.1.4
\end{verbatim}

Согласно \href{https://www.openmp.org/resources/openmp-compilers-tools/}{официальной документации} даная версия компилятора поддерживает \textit{OpenMP 5.0} (необходимо для сравнения с первой лабораторной)


% ---------------------------------- Работа с OpenMP ----------------------------------

\section{Работа с \textit{MPI}}

Стоит отметить, что в используемой мной среде для компиляции программ, поддерживающих \textit{MPI} обязательно использование специального компилятора \textit{mpicc}.

Вывод программы в однопоточном режиме:
\begin{tiny}
\begin{verbatim}
MPI Comm Size: 1;
MPI Comm Rank: 0;
Processor #0 has array: 788159773 2052308573 1377030627 1699618045 676203154 299802456 1767965774 1838448927 1686836254 1335355396
Processor #0 checks items 0 .. 9;
Processor #0 reports local max = 2052308573;

*** Global Maximum is 2052308573;
MPI Finalize returned (0);
\end{verbatim}
\end{tiny}

Вывод программы в многопоточном режиме при запуске с 4-мя процессами:
\begin{tiny}
\begin{verbatim}
MPI Comm Size: 4;
MPI Comm Rank: 2;
MPI Comm Size: 4;
MPI Comm Rank: 3;
MPI Comm Size: 4;
MPI Comm Rank: 0;
Processor #0 has array: 788159773 2052308573 1377030627 1699618045 676203154 299802456 1767965774 1838448927 1686836254 1335355396
Processor #0 checks items 0 .. 1;
Processor #0 reports local max = 2052308573;
Processor #3 has array: 788159773 2052308573 1377030627 1699618045 676203154 299802456 1767965774 1838448927 1686836254 1335355396
Processor #3 checks items 7 .. 9;
Processor #3 reports local max = 1838448927;
MPI Comm Size: 4;
MPI Comm Rank: 1;
Processor #1 has array: 788159773 2052308573 1377030627 1699618045 676203154 299802456 1767965774 1838448927 1686836254 1335355396
Processor #1 checks items 2 .. 4;
Processor #1 reports local max = 1699618045;
Processor #2 has array: 788159773 2052308573 1377030627 1699618045 676203154 299802456 1767965774 1838448927 1686836254 1335355396
Processor #2 checks items 5 .. 6;
Processor #2 reports local max = 1767965774;
MPI Finalize returned (0);

*** Global Maximum is 2052308573;
MPI Finalize returned (0);
MPI Finalize returned (0);
MPI Finalize returned (0);
\end{verbatim}
\end{tiny}


% ---------------------------------- Сравнение ----------------------------------

\section{Скорость \textit{MPI}}

\subsection{Программные коды}

Использовался код программы:

\lstinputlisting[language=C, basicstyle=\footnotesize]{src/main.c}
\vspace{0.5cm}

И небольшой скрипт для сбора данных в \textit{.csv}:

\lstinputlisting[language=Python, basicstyle=\footnotesize]{src/main.py}
\vspace{0.5cm}

\subsection{Экспериментальные данные}

В программе так же использовалось по 10 запусков на количество процессов.

\vspace{0.3cm}

\begin{tikzpicture}
 \begin{axis}[
    xlabel={Число процессов},
    ylabel={Время (мс)},
    legend pos=north east,
  ]
  \addplot table [x=Threads, y=Worst (ms), col sep=comma] {data/mpi_data.csv};
  \addplot table [x=Threads, y=Best (ms), col sep=comma] {data/mpi_data.csv};
  \addplot table [x=Threads, y=Average (ms), col sep=comma] {data/mpi_data.csv};
  \legend{Худшее время, Лучшее время, Среднее время}
 \end{axis}
\end{tikzpicture}

\vspace{0.3cm}

Видно, что в среднем программа работает быстрее, хоть и пик её производительности остается прежним. Рассмотрим случай с оптимизациями (аналогично первой лабораторной):

\vspace{0.3cm}

\begin{tikzpicture}
 \begin{axis}[
    xlabel={Число процессов},
    ylabel={Время (мс)},
    legend pos=north east,
  ]
  \addplot table [x=Threads, y=Worst (ms), col sep=comma] {data/mpi_optimize.csv};
  \addplot table [x=Threads, y=Best (ms), col sep=comma] {data/mpi_optimize.csv};
  \addplot table [x=Threads, y=Average (ms), col sep=comma] {data/mpi_optimize.csv};
  \legend{Худшее время, Лучшее время, Среднее время}
 \end{axis}
\end{tikzpicture}

\vspace{0.3cm}

Прирост производительности в \textit{MPI} в отличие от \textit{OpenMP} положителен. Эффективность прироста за каждое число процессов относительно 1:

\begin{tikzpicture}
 \begin{axis}[
    xlabel={Число процессов},
    ylabel={Прирост (\%)},
    ybar interval=0.7,
  ]
  \addplot table [x index=0, y index=1, col sep=comma] {data/mpi_compare.csv};
 \end{axis}
\end{tikzpicture}


% ---------------------------------- Сравнение ----------------------------------

\section{Сравнение \textit{MPI} и \textit{OpenMP}}

Сравним время, для различного числа процессов/потоков:

\vspace{0.3cm}

\begin{tikzpicture}
 \begin{axis}[
    xlabel={Число процессов/потоков},
    ylabel={Время (мс)},
    legend pos=north east,
  ]
  \addplot table [x=Threads, y=Average (ms), col sep=comma] {data/mpi_data.csv};
  \addplot table [x=Threads, y=Average (ms), col sep=comma] {data/data.csv};
  \legend{\textit{MPI}, \textit{OpenMP}}
 \end{axis}
\end{tikzpicture}

Неоспоримое превосходство MPI (используются результаты из первой рабораторной)

% ---------------------------------- Заключение ----------------------------------

\section{Заключение}
В данной работе была исследована работа с \textit{MPI}. Был написан скрипт, собирающий информацию о времени исполнения программы.

В ходе работы было выяснено, что программа, написанная в первой лабораторной работе с применением \textit{OpenMP} выполняется гораздо медленнее.

Несмотря на это в прошлой лабораторной мной были изучены типы распределения нагрузки, которые возможно помогли бы приблизить результаты \textit{OpenMP} к результатам \textit{MPI}.


\end{document}
